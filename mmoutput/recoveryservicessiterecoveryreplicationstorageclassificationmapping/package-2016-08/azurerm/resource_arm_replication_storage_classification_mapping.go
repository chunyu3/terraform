// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Magic Modules and manual
//     changes will be clobbered when the file is regenerated.
//
//     Please read more about how to change this file at
//     https://github.com/Azure/magic-module-specs
//
// ----------------------------------------------------------------------------

package azurerm



func resourceArmReplicationStorageClassificationMapping() *schema.Resource {
    return &schema.Resource{
        Create: resourceArmReplicationStorageClassificationMappingCreateUpdate,
        Read: resourceArmReplicationStorageClassificationMappingRead,
        Update: resourceArmReplicationStorageClassificationMappingCreateUpdate,
        Delete: resourceArmReplicationStorageClassificationMappingDelete,

        Importer: &schema.ResourceImporter{
            State: schema.ImportStatePassthrough,
        },


        Schema: map[string]*schema.Schema{
            "name": {
                Type: schema.TypeString,
                Computed: true,
            },

            "location": azure.SchemaLocation(),

            "resource_group": azure.SchemaResourceGroupNameDiffSuppress(),

            "fabric_name": {
                Type: schema.TypeString,
                Required: true,
                ForceNew: true,
                ValidateFunc: validate.NoEmptyStrings,
            },

            "resource_name": {
                Type: schema.TypeString,
                Required: true,
                ForceNew: true,
                ValidateFunc: validate.NoEmptyStrings,
            },

            "storage_classification_mapping_name": {
                Type: schema.TypeString,
                Required: true,
                ForceNew: true,
                ValidateFunc: validate.NoEmptyStrings,
            },

            "storage_classification_name": {
                Type: schema.TypeString,
                Required: true,
                ForceNew: true,
                ValidateFunc: validate.NoEmptyStrings,
            },

            "target_storage_classification_id": {
                Type: schema.TypeString,
                Optional: true,
            },

            "type": {
                Type: schema.TypeString,
                Computed: true,
            },
        },
    }
}

func resourceArmReplicationStorageClassificationMappingCreateUpdate(d *schema.ResourceData, meta interface{}) error {
    client := meta.(*ArmClient).replicationStorageClassificationMappingsClient
    ctx := meta.(*ArmClient).StopContext

    resourceGroup := d.Get("resource_group").(string)
    fabricName := d.Get("fabric_name").(string)
    resourceName := d.Get("resource_name").(string)
    storageClassificationMappingName := d.Get("storage_classification_mapping_name").(string)
    storageClassificationName := d.Get("storage_classification_name").(string)

    if features.ShouldResourcesBeImported() && d.IsNewResource() {
        existing, err := client.Get(ctx, resourceName, resourceGroup, fabricName, storageClassificationName, storageClassificationMappingName)
        if err != nil {
            if !utils.ResponseWasNotFound(existing.Response) {
                return fmt.Errorf("Error checking for present of existing Replication Storage Classification Mapping (Storage Classification Mapping Name %q / Storage Classification Name %q / Fabric Name %q / Resource Group %q / Resource Name %q): %+v", storageClassificationMappingName, storageClassificationName, fabricName, resourceGroup, resourceName, err)
            }
        }
        if existing.ID != nil && *existing.ID != "" {
            return tf.ImportAsExistsError("azurerm_replication_storage_classification_mapping", *existing.ID)
        }
    }

    targetStorageClassificationId := d.Get("target_storage_classification_id").(string)

    pairingInput := recoveryservicessiterecovery.StorageClassificationMappingInput{
        StorageMappingInputProperties: &recoveryservicessiterecovery.StorageMappingInputProperties{
            TargetStorageClassificationID: utils.String(targetStorageClassificationId),
        },
    }


    future, err := client.Create(ctx, resourceName, resourceGroup, fabricName, storageClassificationName, storageClassificationMappingName, pairingInput)
    if err != nil {
        return fmt.Errorf("Error creating Replication Storage Classification Mapping (Storage Classification Mapping Name %q / Storage Classification Name %q / Fabric Name %q / Resource Group %q / Resource Name %q): %+v", storageClassificationMappingName, storageClassificationName, fabricName, resourceGroup, resourceName, err)
    }
    if err = future.WaitForCompletionRef(ctx, client.Client); err != nil {
        return fmt.Errorf("Error waiting for creation of Replication Storage Classification Mapping (Storage Classification Mapping Name %q / Storage Classification Name %q / Fabric Name %q / Resource Group %q / Resource Name %q): %+v", storageClassificationMappingName, storageClassificationName, fabricName, resourceGroup, resourceName, err)
    }


    resp, err := client.Get(ctx, resourceName, resourceGroup, fabricName, storageClassificationName, storageClassificationMappingName)
    if err != nil {
        return fmt.Errorf("Error retrieving Replication Storage Classification Mapping (Storage Classification Mapping Name %q / Storage Classification Name %q / Fabric Name %q / Resource Group %q / Resource Name %q): %+v", storageClassificationMappingName, storageClassificationName, fabricName, resourceGroup, resourceName, err)
    }
    if resp.ID == nil {
        return fmt.Errorf("Cannot read Replication Storage Classification Mapping (Storage Classification Mapping Name %q / Storage Classification Name %q / Fabric Name %q / Resource Group %q / Resource Name %q) ID", storageClassificationMappingName, storageClassificationName, fabricName, resourceGroup, resourceName)
    }
    d.SetId(*resp.ID)

    return resourceArmReplicationStorageClassificationMappingRead(d, meta)
}

func resourceArmReplicationStorageClassificationMappingRead(d *schema.ResourceData, meta interface{}) error {
    client := meta.(*ArmClient).replicationStorageClassificationMappingsClient
    ctx := meta.(*ArmClient).StopContext

    id, err := azure.ParseAzureResourceID(d.Id())
    if err != nil {
        return err
    }
    resourceName := id.Path["vaults"]
    resourceGroup := id.ResourceGroup
    fabricName := id.Path["replicationFabrics"]
    storageClassificationName := id.Path["replicationStorageClassifications"]
    storageClassificationMappingName := id.Path["replicationStorageClassificationMappings"]

    resp, err := client.Get(ctx, resourceName, resourceGroup, fabricName, storageClassificationName, storageClassificationMappingName)
    if err != nil {
        if utils.ResponseWasNotFound(resp.Response) {
            log.Printf("[INFO] Replication Storage Classification Mapping %q does not exist - removing from state", d.Id())
            d.SetId("")
            return nil
        }
        return fmt.Errorf("Error reading Replication Storage Classification Mapping (Storage Classification Mapping Name %q / Storage Classification Name %q / Fabric Name %q / Resource Group %q / Resource Name %q): %+v", storageClassificationMappingName, storageClassificationName, fabricName, resourceGroup, resourceName, err)
    }


    d.Set("name", resp.Name)
    d.Set("resource_group", resourceGroup)
    if location := resp.Location; location != nil {
        d.Set("location", azure.NormalizeLocation(*location))
    }
    d.Set("fabric_name", fabricName)
    d.Set("resource_name", resourceName)
    d.Set("storage_classification_mapping_name", storageClassificationMappingName)
    d.Set("storage_classification_name", storageClassificationName)
    if storageMappingInputProperties := resp.StorageMappingInputProperties; storageMappingInputProperties != nil {
        d.Set("target_storage_classification_id", storageMappingInputProperties.TargetStorageClassificationID)
    }
    d.Set("type", resp.Type)

    return nil
}


func resourceArmReplicationStorageClassificationMappingDelete(d *schema.ResourceData, meta interface{}) error {
    client := meta.(*ArmClient).replicationStorageClassificationMappingsClient
    ctx := meta.(*ArmClient).StopContext


    id, err := azure.ParseAzureResourceID(d.Id())
    if err != nil {
        return err
    }
    resourceName := id.Path["vaults"]
    resourceGroup := id.ResourceGroup
    fabricName := id.Path["replicationFabrics"]
    storageClassificationName := id.Path["replicationStorageClassifications"]
    storageClassificationMappingName := id.Path["replicationStorageClassificationMappings"]

    future, err := client.Delete(ctx, resourceName, resourceGroup, fabricName, storageClassificationName, storageClassificationMappingName)
    if err != nil {
        if response.WasNotFound(future.Response()) {
            return nil
        }
        return fmt.Errorf("Error deleting Replication Storage Classification Mapping (Storage Classification Mapping Name %q / Storage Classification Name %q / Fabric Name %q / Resource Group %q / Resource Name %q): %+v", storageClassificationMappingName, storageClassificationName, fabricName, resourceGroup, resourceName, err)
    }

    if err = future.WaitForCompletionRef(ctx, client.Client); err != nil {
        if !response.WasNotFound(future.Response()) {
            return fmt.Errorf("Error waiting for deleting Replication Storage Classification Mapping (Storage Classification Mapping Name %q / Storage Classification Name %q / Fabric Name %q / Resource Group %q / Resource Name %q): %+v", storageClassificationMappingName, storageClassificationName, fabricName, resourceGroup, resourceName, err)
        }
    }

    return nil
}
