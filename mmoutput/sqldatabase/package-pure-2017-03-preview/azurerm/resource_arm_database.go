// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Magic Modules and manual
//     changes will be clobbered when the file is regenerated.
//
//     Please read more about how to change this file at
//     https://github.com/Azure/magic-module-specs
//
// ----------------------------------------------------------------------------

package azurerm



func resourceArmDatabase() *schema.Resource {
    return &schema.Resource{
        Create: resourceArmDatabaseCreate,
        Read: resourceArmDatabaseRead,
        Update: resourceArmDatabaseUpdate,
        Delete: resourceArmDatabaseDelete,

        Importer: &schema.ResourceImporter{
            State: schema.ImportStatePassthrough,
        },


        Schema: map[string]*schema.Schema{
            "name": {
                Type: schema.TypeString,
                Computed: true,
            },

            "location": azure.SchemaLocation(),

            "resource_group": azure.SchemaResourceGroupNameDiffSuppress(),

            "database_name": {
                Type: schema.TypeString,
                Required: true,
                ForceNew: true,
                ValidateFunc: validate.NoEmptyStrings,
            },

            "server_name": {
                Type: schema.TypeString,
                Required: true,
                ForceNew: true,
                ValidateFunc: validate.NoEmptyStrings,
            },

            "catalog_collation": {
                Type: schema.TypeString,
                Optional: true,
                ValidateFunc: validation.StringInSlice([]string{
                    string(sql.DATABASE_DEFAULT),
                    string(sql.SQL_Latin1_General_CP1_CI_AS),
                }, false),
                Default: string(sql.DATABASE_DEFAULT),
            },

            "collation": {
                Type: schema.TypeString,
                Optional: true,
            },

            "create_mode": {
                Type: schema.TypeString,
                Optional: true,
                ValidateFunc: validation.StringInSlice([]string{
                    string(sql.Default),
                    string(sql.Copy),
                    string(sql.Secondary),
                    string(sql.OnlineSecondary),
                    string(sql.PointInTimeRestore),
                    string(sql.Restore),
                    string(sql.Recovery),
                    string(sql.RestoreExternalBackup),
                    string(sql.RestoreExternalBackupSecondary),
                    string(sql.RestoreLongTermRetentionBackup),
                }, false),
                Default: string(sql.Default),
            },

            "elastic_pool_id": {
                Type: schema.TypeString,
                Optional: true,
            },

            "long_term_retention_backup_resource_id": {
                Type: schema.TypeString,
                Optional: true,
            },

            "max_size_bytes": {
                Type: schema.TypeInt,
                Optional: true,
            },

            "recoverable_database_id": {
                Type: schema.TypeString,
                Optional: true,
            },

            "recovery_services_recovery_point_id": {
                Type: schema.TypeString,
                Optional: true,
            },

            "restorable_dropped_database_id": {
                Type: schema.TypeString,
                Optional: true,
            },

            "restore_point_in_time": {
                Type: schema.TypeString,
                Optional: true,
                ValidateFunc: validateRFC3339Date,
            },

            "sample_name": {
                Type: schema.TypeString,
                Optional: true,
                ValidateFunc: validation.StringInSlice([]string{
                    string(sql.AdventureWorksLT),
                    string(sql.WideWorldImportersStd),
                    string(sql.WideWorldImportersFull),
                }, false),
                Default: string(sql.AdventureWorksLT),
            },

            "sku": {
                Type: schema.TypeList,
                Optional: true,
                MaxItems: 1,
                Elem: &schema.Resource{
                    Schema: map[string]*schema.Schema{
                        "name": {
                            Type: schema.TypeString,
                            Required: true,
                            ValidateFunc: validate.NoEmptyStrings,
                        },
                        "capacity": {
                            Type: schema.TypeInt,
                            Optional: true,
                        },
                        "family": {
                            Type: schema.TypeString,
                            Optional: true,
                        },
                        "size": {
                            Type: schema.TypeString,
                            Optional: true,
                        },
                        "tier": {
                            Type: schema.TypeString,
                            Optional: true,
                        },
                    },
                },
            },

            "source_database_deletion_date": {
                Type: schema.TypeString,
                Optional: true,
                ValidateFunc: validateRFC3339Date,
            },

            "source_database_id": {
                Type: schema.TypeString,
                Optional: true,
            },

            "zone_redundant": {
                Type: schema.TypeBool,
                Optional: true,
            },

            "creation_date": {
                Type: schema.TypeString,
                Computed: true,
            },

            "current_service_objective_name": {
                Type: schema.TypeString,
                Computed: true,
            },

            "database_id": {
                Type: schema.TypeString,
                Computed: true,
            },

            "default_secondary_location": {
                Type: schema.TypeString,
                Computed: true,
            },

            "failover_group_id": {
                Type: schema.TypeString,
                Computed: true,
            },

            "kind": {
                Type: schema.TypeString,
                Computed: true,
            },

            "status": {
                Type: schema.TypeString,
                Computed: true,
            },

            "type": {
                Type: schema.TypeString,
                Computed: true,
            },

            "tags": tags.Schema(),
        },
    }
}

func resourceArmDatabaseCreate(d *schema.ResourceData, meta interface{}) error {
    client := meta.(*ArmClient).databasesClient
    ctx := meta.(*ArmClient).StopContext

    resourceGroup := d.Get("resource_group").(string)
    databaseName := d.Get("database_name").(string)
    serverName := d.Get("server_name").(string)

    if features.ShouldResourcesBeImported() && d.IsNewResource() {
        existing, err := client.Get(ctx, resourceGroup, serverName, databaseName)
        if err != nil {
            if !utils.ResponseWasNotFound(existing.Response) {
                return fmt.Errorf("Error checking for present of existing Database (Database Name %q / Server Name %q / Resource Group %q): %+v", databaseName, serverName, resourceGroup, err)
            }
        }
        if existing.ID != nil && *existing.ID != "" {
            return tf.ImportAsExistsError("azurerm_database", *existing.ID)
        }
    }

    location := azure.NormalizeLocation(d.Get("location").(string))
    catalogCollation := d.Get("catalog_collation").(string)
    collation := d.Get("collation").(string)
    createMode := d.Get("create_mode").(string)
    elasticPoolId := d.Get("elastic_pool_id").(string)
    longTermRetentionBackupResourceId := d.Get("long_term_retention_backup_resource_id").(string)
    maxSizeBytes := d.Get("max_size_bytes").(int)
    recoverableDatabaseId := d.Get("recoverable_database_id").(string)
    recoveryServicesRecoveryPointId := d.Get("recovery_services_recovery_point_id").(string)
    restorableDroppedDatabaseId := d.Get("restorable_dropped_database_id").(string)
    restorePointInTime := d.Get("restore_point_in_time").(string)
    sampleName := d.Get("sample_name").(string)
    sku := d.Get("sku").([]interface{})
    sourceDatabaseDeletionDate := d.Get("source_database_deletion_date").(string)
    sourceDatabaseId := d.Get("source_database_id").(string)
    zoneRedundant := d.Get("zone_redundant").(bool)
    t := d.Get("tags").(map[string]interface{})

    parameters := sql.Database{
        Location: utils.String(location),
        DatabaseProperties: &sql.DatabaseProperties{
            CatalogCollation: sql.CatalogCollationType(catalogCollation),
            Collation: utils.String(collation),
            CreateMode: sql.CreateMode(createMode),
            ElasticPoolID: utils.String(elasticPoolId),
            LongTermRetentionBackupResourceID: utils.String(longTermRetentionBackupResourceId),
            MaxSizeBytes: utils.Int64(int64(maxSizeBytes)),
            RecoverableDatabaseID: utils.String(recoverableDatabaseId),
            RecoveryServicesRecoveryPointID: utils.String(recoveryServicesRecoveryPointId),
            RestorableDroppedDatabaseID: utils.String(restorableDroppedDatabaseId),
            RestorePointInTime: convertStringToDate(restorePointInTime),
            SampleName: sql.SampleName(sampleName),
            SourceDatabaseDeletionDate: convertStringToDate(sourceDatabaseDeletionDate),
            SourceDatabaseID: utils.String(sourceDatabaseId),
            ZoneRedundant: utils.Bool(zoneRedundant),
        },
        Sku: expandArmDatabaseSku(sku),
        Tags: tags.Expand(t),
    }


    future, err := client.CreateOrUpdate(ctx, resourceGroup, serverName, databaseName, parameters)
    if err != nil {
        return fmt.Errorf("Error creating Database (Database Name %q / Server Name %q / Resource Group %q): %+v", databaseName, serverName, resourceGroup, err)
    }
    if err = future.WaitForCompletionRef(ctx, client.Client); err != nil {
        return fmt.Errorf("Error waiting for creation of Database (Database Name %q / Server Name %q / Resource Group %q): %+v", databaseName, serverName, resourceGroup, err)
    }


    resp, err := client.Get(ctx, resourceGroup, serverName, databaseName)
    if err != nil {
        return fmt.Errorf("Error retrieving Database (Database Name %q / Server Name %q / Resource Group %q): %+v", databaseName, serverName, resourceGroup, err)
    }
    if resp.ID == nil {
        return fmt.Errorf("Cannot read Database (Database Name %q / Server Name %q / Resource Group %q) ID", databaseName, serverName, resourceGroup)
    }
    d.SetId(*resp.ID)

    return resourceArmDatabaseRead(d, meta)
}

func resourceArmDatabaseRead(d *schema.ResourceData, meta interface{}) error {
    client := meta.(*ArmClient).databasesClient
    ctx := meta.(*ArmClient).StopContext

    id, err := azure.ParseAzureResourceID(d.Id())
    if err != nil {
        return err
    }
    resourceGroup := id.ResourceGroup
    serverName := id.Path["servers"]
    databaseName := id.Path["databases"]

    resp, err := client.Get(ctx, resourceGroup, serverName, databaseName)
    if err != nil {
        if utils.ResponseWasNotFound(resp.Response) {
            log.Printf("[INFO] Database %q does not exist - removing from state", d.Id())
            d.SetId("")
            return nil
        }
        return fmt.Errorf("Error reading Database (Database Name %q / Server Name %q / Resource Group %q): %+v", databaseName, serverName, resourceGroup, err)
    }


    d.Set("name", resp.Name)
    d.Set("resource_group", resourceGroup)
    if location := resp.Location; location != nil {
        d.Set("location", azure.NormalizeLocation(*location))
    }
    if databaseProperties := resp.DatabaseProperties; databaseProperties != nil {
        d.Set("catalog_collation", string(databaseProperties.CatalogCollation))
        d.Set("collation", databaseProperties.Collation)
        d.Set("create_mode", string(databaseProperties.CreateMode))
        d.Set("creation_date", (databaseProperties.CreationDate).String())
        d.Set("current_service_objective_name", databaseProperties.CurrentServiceObjectiveName)
        d.Set("database_id", databaseProperties.DatabaseID)
        d.Set("default_secondary_location", databaseProperties.DefaultSecondaryLocation)
        d.Set("elastic_pool_id", databaseProperties.ElasticPoolID)
        d.Set("failover_group_id", databaseProperties.FailoverGroupID)
        d.Set("long_term_retention_backup_resource_id", databaseProperties.LongTermRetentionBackupResourceID)
        d.Set("max_size_bytes", int(*databaseProperties.MaxSizeBytes))
        d.Set("recoverable_database_id", databaseProperties.RecoverableDatabaseID)
        d.Set("recovery_services_recovery_point_id", databaseProperties.RecoveryServicesRecoveryPointID)
        d.Set("restorable_dropped_database_id", databaseProperties.RestorableDroppedDatabaseID)
        d.Set("restore_point_in_time", (databaseProperties.RestorePointInTime).String())
        d.Set("sample_name", string(databaseProperties.SampleName))
        d.Set("source_database_deletion_date", (databaseProperties.SourceDatabaseDeletionDate).String())
        d.Set("source_database_id", databaseProperties.SourceDatabaseID)
        d.Set("status", string(databaseProperties.Status))
        d.Set("zone_redundant", databaseProperties.ZoneRedundant)
    }
    d.Set("database_name", databaseName)
    d.Set("kind", resp.Kind)
    d.Set("server_name", serverName)
    if err := d.Set("sku", flattenArmDatabaseSku(resp.Sku)); err != nil {
        return fmt.Errorf("Error setting `sku`: %+v", err)
    }
    d.Set("type", resp.Type)

    return tags.FlattenAndSet(d, resp.Tags)
}

func resourceArmDatabaseUpdate(d *schema.ResourceData, meta interface{}) error {
    client := meta.(*ArmClient).databasesClient
    ctx := meta.(*ArmClient).StopContext

    resourceGroup := d.Get("resource_group").(string)
    catalogCollation := d.Get("catalog_collation").(string)
    collation := d.Get("collation").(string)
    createMode := d.Get("create_mode").(string)
    databaseName := d.Get("database_name").(string)
    elasticPoolId := d.Get("elastic_pool_id").(string)
    longTermRetentionBackupResourceId := d.Get("long_term_retention_backup_resource_id").(string)
    maxSizeBytes := d.Get("max_size_bytes").(int)
    recoverableDatabaseId := d.Get("recoverable_database_id").(string)
    recoveryServicesRecoveryPointId := d.Get("recovery_services_recovery_point_id").(string)
    restorableDroppedDatabaseId := d.Get("restorable_dropped_database_id").(string)
    restorePointInTime := d.Get("restore_point_in_time").(string)
    sampleName := d.Get("sample_name").(string)
    serverName := d.Get("server_name").(string)
    sku := d.Get("sku").([]interface{})
    sourceDatabaseDeletionDate := d.Get("source_database_deletion_date").(string)
    sourceDatabaseId := d.Get("source_database_id").(string)
    zoneRedundant := d.Get("zone_redundant").(bool)
    t := d.Get("tags").(map[string]interface{})

    parameters := sql.Database{
        Location: utils.String(location),
        DatabaseProperties: &sql.DatabaseProperties{
            CatalogCollation: sql.CatalogCollationType(catalogCollation),
            Collation: utils.String(collation),
            CreateMode: sql.CreateMode(createMode),
            ElasticPoolID: utils.String(elasticPoolId),
            LongTermRetentionBackupResourceID: utils.String(longTermRetentionBackupResourceId),
            MaxSizeBytes: utils.Int64(int64(maxSizeBytes)),
            RecoverableDatabaseID: utils.String(recoverableDatabaseId),
            RecoveryServicesRecoveryPointID: utils.String(recoveryServicesRecoveryPointId),
            RestorableDroppedDatabaseID: utils.String(restorableDroppedDatabaseId),
            RestorePointInTime: convertStringToDate(restorePointInTime),
            SampleName: sql.SampleName(sampleName),
            SourceDatabaseDeletionDate: convertStringToDate(sourceDatabaseDeletionDate),
            SourceDatabaseID: utils.String(sourceDatabaseId),
            ZoneRedundant: utils.Bool(zoneRedundant),
        },
        Sku: expandArmDatabaseSku(sku),
        Tags: tags.Expand(t),
    }


    future, err := client.Update(ctx, resourceGroup, serverName, databaseName, parameters)
    if err != nil {
        return fmt.Errorf("Error updating Database (Database Name %q / Server Name %q / Resource Group %q): %+v", databaseName, serverName, resourceGroup, err)
    }
    if err = future.WaitForCompletionRef(ctx, client.Client); err != nil {
        return fmt.Errorf("Error waiting for update of Database (Database Name %q / Server Name %q / Resource Group %q): %+v", databaseName, serverName, resourceGroup, err)
    }

    return resourceArmDatabaseRead(d, meta)
}

func resourceArmDatabaseDelete(d *schema.ResourceData, meta interface{}) error {
    client := meta.(*ArmClient).databasesClient
    ctx := meta.(*ArmClient).StopContext


    id, err := azure.ParseAzureResourceID(d.Id())
    if err != nil {
        return err
    }
    resourceGroup := id.ResourceGroup
    serverName := id.Path["servers"]
    databaseName := id.Path["databases"]

    future, err := client.Delete(ctx, resourceGroup, serverName, databaseName)
    if err != nil {
        if response.WasNotFound(future.Response()) {
            return nil
        }
        return fmt.Errorf("Error deleting Database (Database Name %q / Server Name %q / Resource Group %q): %+v", databaseName, serverName, resourceGroup, err)
    }

    if err = future.WaitForCompletionRef(ctx, client.Client); err != nil {
        if !response.WasNotFound(future.Response()) {
            return fmt.Errorf("Error waiting for deleting Database (Database Name %q / Server Name %q / Resource Group %q): %+v", databaseName, serverName, resourceGroup, err)
        }
    }

    return nil
}

func convertStringToDate(input interface{}) *date.Time {
  v := input.(string)

  dateTime, err := date.ParseTime(time.RFC3339, v)
  if err != nil {
      log.Printf("[ERROR] Cannot convert an invalid string to RFC3339 date %q: %+v", v, err)
      return nil
  }

  result := date.Time{
      Time: dateTime,
  }
  return &result
}

func expandArmDatabaseSku(input []interface{}) *sql.Sku {
    if len(input) == 0 {
        return nil
    }
    v := input[0].(map[string]interface{})

    name := v["name"].(string)
    tier := v["tier"].(string)
    size := v["size"].(string)
    family := v["family"].(string)
    capacity := v["capacity"].(int)

    result := sql.Sku{
        Capacity: utils.Int32(int32(capacity)),
        Family: utils.String(family),
        Name: utils.String(name),
        Size: utils.String(size),
        Tier: utils.String(tier),
    }
    return &result
}


func flattenArmDatabaseSku(input *sql.Sku) []interface{} {
    if input == nil {
        return make([]interface{}, 0)
    }

    result := make(map[string]interface{})

    if name := input.Name; name != nil {
        result["name"] = *name
    }
    if capacity := input.Capacity; capacity != nil {
        result["capacity"] = int(*capacity)
    }
    if family := input.Family; family != nil {
        result["family"] = *family
    }
    if size := input.Size; size != nil {
        result["size"] = *size
    }
    if tier := input.Tier; tier != nil {
        result["tier"] = *tier
    }

    return []interface{}{result}
}
